{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vik/.virtualenvs/nnets/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import functorch\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "sys.path.append(os.path.abspath(\"../../data\"))\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 8\n",
    "SP_VOCAB_SIZE = 1000\n",
    "VOCAB_SIZE=1002\n",
    "CHUNK_LENGTH = 12"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cnn_dailymail (/Users/vik/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n",
      "100%|██████████| 3/3 [00:00<00:00, 155.77it/s]\n",
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=tokens.txt --model_prefix=cnn --vocab_size=1000 --model_type=unigram\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: tokens.txt\n",
      "  input_format: \n",
      "  model_prefix: cnn\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 1000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(319) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(174) LOG(INFO) Loading corpus: tokens.txt\n",
      "trainer_interface.cc(375) LOG(INFO) Loaded all 4891 sentences\n",
      "trainer_interface.cc(390) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(390) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(390) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(395) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(456) LOG(INFO) all chars count=353186\n",
      "trainer_interface.cc(467) LOG(INFO) Done: 99.9578% characters are covered.\n",
      "trainer_interface.cc(477) LOG(INFO) Alphabet size=69\n",
      "trainer_interface.cc(478) LOG(INFO) Final character coverage=0.999578\n",
      "trainer_interface.cc(510) LOG(INFO) Done! preprocessed 4891 sentences.\n",
      "unigram_model_trainer.cc(138) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(142) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(193) LOG(INFO) Initialized 24313 seed sentencepieces\n",
      "trainer_interface.cc(516) LOG(INFO) Tokenizing input sentences with whitespace: 4891\n",
      "trainer_interface.cc(526) LOG(INFO) Done! 13988\n",
      "unigram_model_trainer.cc(488) LOG(INFO) Using 13988 sentences for EM training\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=9933 obj=12.269 num_tokens=29046 num_tokens/piece=2.92419\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=8588 obj=10.4791 num_tokens=29306 num_tokens/piece=3.41244\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=6438 obj=10.5173 num_tokens=31293 num_tokens/piece=4.86067\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=6429 obj=10.4476 num_tokens=31320 num_tokens/piece=4.87168\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=4821 obj=10.7422 num_tokens=34496 num_tokens/piece=7.15536\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=4821 obj=10.6511 num_tokens=34504 num_tokens/piece=7.15702\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=3615 obj=11.064 num_tokens=38156 num_tokens/piece=10.5549\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=3615 obj=10.9584 num_tokens=38154 num_tokens/piece=10.5544\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=2711 obj=11.4504 num_tokens=42048 num_tokens/piece=15.5101\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=2711 obj=11.3421 num_tokens=42046 num_tokens/piece=15.5094\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=2033 obj=11.8841 num_tokens=45925 num_tokens/piece=22.5898\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=2033 obj=11.775 num_tokens=45921 num_tokens/piece=22.5878\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=1524 obj=12.3539 num_tokens=49519 num_tokens/piece=32.4928\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=1524 obj=12.2393 num_tokens=49532 num_tokens/piece=32.5013\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=1143 obj=12.8701 num_tokens=52687 num_tokens/piece=46.0954\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=1143 obj=12.748 num_tokens=52684 num_tokens/piece=46.0927\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=1100 obj=12.8227 num_tokens=53202 num_tokens/piece=48.3655\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=1100 obj=12.8041 num_tokens=53201 num_tokens/piece=48.3645\n",
      "trainer_interface.cc(604) LOG(INFO) Saving model: cnn.model\n",
      "trainer_interface.cc(615) LOG(INFO) Saving vocabs: cnn.vocab\n"
     ]
    }
   ],
   "source": [
    "from cnn_data import generate_data, decode_batch\n",
    "\n",
    "train, valid, test = generate_data(train_length=1000, valid_length=250, vocab_size=SP_VOCAB_SIZE, batch_size=BATCH_SIZE, chunk_length=CHUNK_LENGTH, device=DEVICE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "class GRUEncoder(nn.Module):\n",
    "    def __init__(self, input_units, hidden_units, output_units):\n",
    "        super(GRUEncoder, self).__init__()\n",
    "        self.input_units = input_units\n",
    "        self.hidden_units = hidden_units\n",
    "\n",
    "        k = 1/math.sqrt(hidden_units)\n",
    "        self.input_weights = nn.Parameter(torch.rand(3, input_units, hidden_units) * 2 * k - k)\n",
    "\n",
    "        self.hidden_weights = nn.Parameter(torch.rand(3, hidden_units, hidden_units) * 2 * k - k)\n",
    "        self.hidden_biases = nn.Parameter(torch.rand(2, 1, hidden_units) * 2 * k - k)\n",
    "\n",
    "        self.output_weight = nn.Parameter(torch.rand(hidden_units, output_units) * 2 * k - k)\n",
    "        self.output_bias = nn.Parameter(torch.rand(1, output_units) * 2 * k - k)\n",
    "\n",
    "    def forward(self, x, prev_hidden):\n",
    "        # Compute the regular RNN forward pass\n",
    "\n",
    "        # Compute update and reset gates for GRU\n",
    "        update_gate = torch.sigmoid(x @ self.input_weights[0,] + prev_hidden @ self.hidden_weights[0,] + self.hidden_biases[0,])\n",
    "        reset_gate = torch.sigmoid(x @ self.input_weights[1,] + prev_hidden @ self.hidden_weights[1,] + self.hidden_biases[1,])\n",
    "\n",
    "        # This is a potential new state based on the reset gate\n",
    "        proposed_state = torch.tanh(x @ self.input_weights[2,] + (prev_hidden * reset_gate) @ self.hidden_weights[2,])\n",
    "        hidden_x = torch.tanh((1-update_gate) * prev_hidden + update_gate * proposed_state)\n",
    "        # Compute output vector\n",
    "        output_y = hidden_x @ self.output_weight + self.output_bias\n",
    "        return hidden_x, output_y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "class GRUDecoder(nn.Module):\n",
    "    def __init__(self, input_units, context_units, hidden_units, output_units):\n",
    "        super(GRUDecoder, self).__init__()\n",
    "        self.input_units = input_units\n",
    "        self.hidden_units = hidden_units\n",
    "        self.output_units = output_units\n",
    "\n",
    "        k = 1/math.sqrt(hidden_units)\n",
    "\n",
    "        self.input_weights = nn.Parameter(torch.rand(3, input_units, hidden_units) * 2 * k - k)\n",
    "        self.hidden_weights = nn.Parameter(torch.rand(3, hidden_units, hidden_units) * 2 * k - k)\n",
    "\n",
    "        self.context_weights = nn.Parameter(torch.rand(3, context_units, hidden_units) * 2 * k - k)\n",
    "\n",
    "        self.hidden_biases = nn.Parameter(torch.rand(2, 1, hidden_units) * 2 * k - k)\n",
    "\n",
    "        self.hidden_attention_weight = nn.Parameter(torch.rand(hidden_units, hidden_units) * 2 * k - k)\n",
    "        self.context_attention_weight = nn.Parameter(torch.rand(context_units, hidden_units) * 2 * k - k)\n",
    "        self.attention_weight = nn.Parameter(torch.rand(1, hidden_units) * 2 * k - k)\n",
    "\n",
    "        self.output_weight = nn.Parameter(torch.rand(hidden_units, output_units) * 2 * k - k)\n",
    "        self.output_bias = nn.Parameter(torch.rand(1, output_units) * 2 * k - k)\n",
    "\n",
    "        self.batched_diag = functorch.vmap(torch.diag)\n",
    "\n",
    "    def forward(self, prev_y, prev_hidden, context):\n",
    "        # Compute attention between the encoder hidden states and the previous decoder hidden state\n",
    "\n",
    "        # Swap batch and sequence\n",
    "        batch_size = context.shape[1]\n",
    "\n",
    "        # Swap axes so the first dimension of context_attn is batch\n",
    "        context_attn = torch.bmm(context.swapaxes(0,1), self.context_attention_weight.unsqueeze(0).expand(batch_size,-1,-1))\n",
    "        # Swap back since prev_hidden is by batch.  This makes the first dim of cross sequence\n",
    "        cross = torch.tanh(context_attn.swapaxes(0,1) + prev_hidden @ self.hidden_attention_weight)\n",
    "        # This will be of dimension batch, sequence_length, 1\n",
    "        attention = torch.bmm(cross.swapaxes(0,1), self.attention_weight.T.unsqueeze(0).expand(batch_size, -1, -1))\n",
    "        # Drop the last singleton dimension\n",
    "        attention = attention.squeeze(2)\n",
    "        # Softmax the predictions\n",
    "        probs = torch.softmax(attention, 0)\n",
    "        diagonalized_probs = self.batched_diag(probs)\n",
    "        positional_contexts = torch.sum(torch.bmm(diagonalized_probs, context.swapaxes(0,1)), dim=1).reshape(batch_size, self.input_units)\n",
    "\n",
    "        # Compute GRU update and reset gates + proposed state and final hidden state\n",
    "        update_gate = torch.sigmoid(prev_y @ self.input_weights[0,] + prev_hidden @ self.hidden_weights[0,] + self.hidden_biases[0,] + positional_contexts @ self.context_weights[0,])\n",
    "        reset_gate = torch.sigmoid(prev_y @ self.input_weights[1,] + prev_hidden @ self.hidden_weights[1,] + self.hidden_biases[1,] + positional_contexts @ self.context_weights[1,])\n",
    "\n",
    "        proposed_state = torch.tanh(prev_y @ self.input_weights[2,] + (prev_hidden * reset_gate) @ self.hidden_weights[2,] + positional_contexts @ self.context_weights[2,])\n",
    "\n",
    "        hidden_x = torch.tanh((1-update_gate) * prev_hidden + update_gate * proposed_state)\n",
    "        # Compute output based on hidden state\n",
    "        output_y = hidden_x @ self.output_weight + self.output_bias\n",
    "        return hidden_x, output_y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, in_sequence_len, out_sequence_len, hidden_units=512, embedding_len=VOCAB_SIZE):\n",
    "        super(Network, self).__init__()\n",
    "        self.in_sequence_len = in_sequence_len\n",
    "        self.out_sequence_len = out_sequence_len\n",
    "        self.hidden_units = hidden_units\n",
    "        self.embedding_len = embedding_len\n",
    "\n",
    "        self.embedding = nn.Embedding(embedding_len, hidden_units)\n",
    "        self.encoder = GRUEncoder(input_units=hidden_units, hidden_units=hidden_units, output_units=embedding_len)\n",
    "        self.decoder = GRUDecoder(input_units=hidden_units, context_units=hidden_units, hidden_units=hidden_units, output_units=embedding_len)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        batch_size = x.shape[0]\n",
    "        # Move batch to the second dimension, so sequence comes first\n",
    "        y = y.swapaxes(0,1)\n",
    "        # Embed the input sequence to reduce dimensionality\n",
    "        embedded = self.embedding(x).swapaxes(0,1)\n",
    "\n",
    "        # Encode the input sequence\n",
    "        # Both tensors will have sequence then batch\n",
    "        enc_hiddens = torch.zeros((1, batch_size, self.hidden_units), device=DEVICE)\n",
    "        enc_outputs = torch.zeros((1, batch_size, self.embedding_len), device=DEVICE)\n",
    "        for j in range(self.in_sequence_len):\n",
    "            hidden, output = self.encoder(embedded[j,:,:], enc_hiddens[j,:,:])\n",
    "            # Add first sequence axis\n",
    "            hidden = hidden.unsqueeze(0)\n",
    "            output = output.unsqueeze(0)\n",
    "            enc_hiddens = torch.cat((enc_hiddens, hidden), dim=0)\n",
    "            enc_outputs = torch.cat((enc_outputs, output), dim=0)\n",
    "\n",
    "        # Decode to the output sequence\n",
    "        # Pass in context\n",
    "        context = enc_hiddens[1:,:,:]\n",
    "        # Both tensors will have the first dimension be the sequence\n",
    "        dec_hiddens = torch.zeros(1, batch_size, self.hidden_units, device=DEVICE)\n",
    "        dec_outputs = torch.zeros((1, batch_size, self.embedding_len), device=DEVICE)\n",
    "        for j in range(self.out_sequence_len):\n",
    "            # Use either the actual previous y (from the input), or the generated y if the input sequence is shorter than the generation steps.\n",
    "            prev_y = y[j,:,:] if y.shape[0] > j else torch.softmax(dec_outputs[j,:,:], dim=1)\n",
    "            # Run embedding over previous y state\n",
    "            prev_y = prev_y.argmax(dim=1).int()\n",
    "            prev_y = self.embedding(prev_y)\n",
    "            hidden, output = self.decoder(prev_y, dec_hiddens[j,:,:], context)\n",
    "            # Add first sequence axis\n",
    "            hidden = hidden.unsqueeze(0)\n",
    "            output= output.unsqueeze(0)\n",
    "            dec_hiddens = torch.cat((dec_hiddens, hidden), dim=0)\n",
    "            dec_outputs = torch.cat((dec_outputs, output), dim=0)\n",
    "\n",
    "        # Move batch back to axis 0\n",
    "        out_hiddens = dec_hiddens[1:].swapaxes(0,1)\n",
    "        out_output = dec_outputs[1:].swapaxes(0,1)\n",
    "        return out_hiddens, out_output\n",
    "\n",
    "def generate(sequence, target):\n",
    "    _, pred = model(sequence, target[:,0,:].unsqueeze(1))\n",
    "    prompts = decode_batch(sequence.cpu(), vocab_size=VOCAB_SIZE)\n",
    "    texts = decode_batch(torch.argmax(pred, dim=2).cpu(), vocab_size=VOCAB_SIZE)\n",
    "    correct_texts = decode_batch(torch.argmax(target, dim=2).cpu(), vocab_size=VOCAB_SIZE)\n",
    "\n",
    "    displays = []\n",
    "    for p, t, ct in zip(prompts, texts, correct_texts):\n",
    "        displays.append(f\"{p} | {ct} | {t}\")\n",
    "    return displays"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "model = Network(CHUNK_LENGTH, CHUNK_LENGTH, hidden_units=512).to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125it [00:27,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW: Georgian president criticizes Gorbach | ev for \"vindicating lies and | ------------\n",
      "19 schoolgirls and two adult | s die in primary school dormitor | ssssssssssss\n",
      "U.S. intelligence point | s to Pakistan agents involved in attack on Indian | ssssssssssss\n",
      "Mother of murdered schoolboy Damilol | a Taylor dies of suspected heart | aaaaaaaaaaaa\n",
      "NEW: Pope Benedict  |  ⁇ VI arrives in Washington for six | be be be be be be be be be be be be\n",
      "Eight Florida teens to be tried as ad | ults in videotaped beating case | ulululululululululululul\n",
      "Judge on Heather Mills: Le | vel of premarital wealth \" | veveveveveveveveveveveve\n",
      "President Harding's illegiti | mate daughter was conceived on couch | mmmmmmmmmmmm\n",
      "Epoch 0 train loss: 208.55217321777343 valid loss: 237.77848327159882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125it [00:28,  4.36it/s]\n",
      "125it [00:28,  4.42it/s]\n",
      "125it [00:27,  4.47it/s]\n",
      "125it [00:28,  4.46it/s]\n",
      "125it [00:28,  4.44it/s]\n",
      "125it [00:28,  4.43it/s]\n",
      "125it [00:29,  4.29it/s]\n",
      "125it [00:29,  4.18it/s]\n",
      "125it [00:27,  4.49it/s]\n",
      "125it [00:27,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW: Georgian president criticizes Gorbach | ev for \"vindicating lies and | evevevevevevevevevevevev\n",
      "19 schoolgirls and two adult | s die in primary school dormitor | ssssssssssss\n",
      "U.S. intelligence point | s to Pakistan agents involved in attack on Indian | ssssssssssss\n",
      "Mother of murdered schoolboy Damilol | a Taylor dies of suspected heart | aaaaaaaaaaaa\n",
      "NEW: Pope Benedict  |  ⁇ VI arrives in Washington for six |  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇ \n",
      "Eight Florida teens to be tried as ad | ults in videotaped beating case | ulululululululululululul\n",
      "Judge on Heather Mills: Le | vel of premarital wealth \" | veveveveveveveveveveveve\n",
      "President Harding's illegiti | mate daughter was conceived on couch | mmmmmmmmmmmm\n",
      "Epoch 10 train loss: 148.43473364257812 valid loss: 234.2144821882248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125it [00:27,  4.48it/s]\n",
      "125it [00:28,  4.35it/s]\n",
      "125it [00:27,  4.58it/s]\n",
      "125it [00:27,  4.55it/s]\n",
      "125it [00:28,  4.45it/s]\n",
      "125it [00:27,  4.48it/s]\n",
      "125it [00:27,  4.53it/s]\n",
      "125it [00:27,  4.55it/s]\n",
      "125it [00:27,  4.55it/s]\n",
      "125it [00:27,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW: Georgian president criticizes Gorbach | ev for \"vindicating lies and | evevevevevevevevevevevev\n",
      "19 schoolgirls and two adult | s die in primary school dormitor | ssssssssssss\n",
      "U.S. intelligence point | s to Pakistan agents involved in attack on Indian | ssssssssssss\n",
      "Mother of murdered schoolboy Damilol | a Taylor dies of suspected heart | aaaaaaaaaaaa\n",
      "NEW: Pope Benedict  |  ⁇ VI arrives in Washington for six |  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇ \n",
      "Eight Florida teens to be tried as ad | ults in videotaped beating case | ulululululululululululul\n",
      "Judge on Heather Mills: Le | vel of premarital wealth \" | veveveveveveveveveveveve\n",
      "President Harding's illegiti | mate daughter was conceived on couch | mmmmmmmmmmmm\n",
      "Epoch 20 train loss: 115.63843781280518 valid loss: 229.0219978094101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125it [00:27,  4.54it/s]\n",
      "125it [00:27,  4.56it/s]\n",
      "125it [00:27,  4.57it/s]\n",
      "125it [00:27,  4.49it/s]\n",
      "125it [00:28,  4.45it/s]\n",
      "125it [00:27,  4.51it/s]\n",
      "125it [00:27,  4.53it/s]\n",
      "125it [00:28,  4.46it/s]\n",
      "125it [00:28,  4.41it/s]\n",
      "125it [00:27,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW: Georgian president criticizes Gorbach | ev for \"vindicating lies and | evevevevevevevevevevevev\n",
      "19 schoolgirls and two adult | s die in primary school dormitor | ssssssssssss\n",
      "U.S. intelligence point | s to Pakistan agents involved in attack on Indian | ssssssssssss\n",
      "Mother of murdered schoolboy Damilol | a Taylor dies of suspected heart | aaaaaaaaaaaa\n",
      "NEW: Pope Benedict  |  ⁇ VI arrives in Washington for six |  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇ \n",
      "Eight Florida teens to be tried as ad | ults in videotaped beating case | ulululululululululululul\n",
      "Judge on Heather Mills: Le | vel of premarital wealth \" | veveveveveveveveveveveve\n",
      "President Harding's illegiti | mate daughter was conceived on couch | mmmmmmmmmmmm\n",
      "Epoch 30 train loss: 110.46447555923461 valid loss: 226.1087828874588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125it [00:27,  4.49it/s]\n",
      "125it [00:27,  4.51it/s]\n",
      "125it [00:28,  4.44it/s]\n",
      "125it [00:27,  4.54it/s]\n",
      "125it [00:27,  4.50it/s]\n",
      "36it [00:08,  4.33it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[54], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(EPOCHS):\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m# Run over the training examples\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m----> 7\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch, (sequence, target) \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28menumerate\u001B[39m(train)):\n\u001B[1;32m      8\u001B[0m         optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m      9\u001B[0m         forced_target \u001B[38;5;241m=\u001B[39m target\n",
      "File \u001B[0;32m~/.virtualenvs/nnets/lib/python3.10/site-packages/tqdm/std.py:1205\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1203\u001B[0m dt \u001B[38;5;241m=\u001B[39m cur_t \u001B[38;5;241m-\u001B[39m last_print_t\n\u001B[1;32m   1204\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dt \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m mininterval \u001B[38;5;129;01mand\u001B[39;00m cur_t \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m min_start_t:\n\u001B[0;32m-> 1205\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mlast_print_n\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1206\u001B[0m     last_print_n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_print_n\n\u001B[1;32m   1207\u001B[0m     last_print_t \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_print_t\n",
      "File \u001B[0;32m~/.virtualenvs/nnets/lib/python3.10/site-packages/tqdm/std.py:1256\u001B[0m, in \u001B[0;36mtqdm.update\u001B[0;34m(self, n)\u001B[0m\n\u001B[1;32m   1254\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ema_dn(dn)\n\u001B[1;32m   1255\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ema_dt(dt)\n\u001B[0;32m-> 1256\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrefresh\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlock_args\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlock_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1257\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdynamic_miniters:\n\u001B[1;32m   1258\u001B[0m     \u001B[38;5;66;03m# If no `miniters` was specified, adjust automatically to the\u001B[39;00m\n\u001B[1;32m   1259\u001B[0m     \u001B[38;5;66;03m# maximum iteration rate seen so far between two prints.\u001B[39;00m\n\u001B[1;32m   1260\u001B[0m     \u001B[38;5;66;03m# e.g.: After running `tqdm.update(5)`, subsequent\u001B[39;00m\n\u001B[1;32m   1261\u001B[0m     \u001B[38;5;66;03m# calls to `tqdm.update()` will only cause an update after\u001B[39;00m\n\u001B[1;32m   1262\u001B[0m     \u001B[38;5;66;03m# at least 5 more iterations.\u001B[39;00m\n\u001B[1;32m   1263\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmaxinterval \u001B[38;5;129;01mand\u001B[39;00m dt \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmaxinterval:\n",
      "File \u001B[0;32m~/.virtualenvs/nnets/lib/python3.10/site-packages/tqdm/std.py:1361\u001B[0m, in \u001B[0;36mtqdm.refresh\u001B[0;34m(self, nolock, lock_args)\u001B[0m\n\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1360\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39macquire()\n\u001B[0;32m-> 1361\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdisplay\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1362\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m nolock:\n\u001B[1;32m   1363\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/.virtualenvs/nnets/lib/python3.10/site-packages/tqdm/std.py:1509\u001B[0m, in \u001B[0;36mtqdm.display\u001B[0;34m(self, msg, pos)\u001B[0m\n\u001B[1;32m   1507\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pos:\n\u001B[1;32m   1508\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmoveto(pos)\n\u001B[0;32m-> 1509\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msp\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__str__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmsg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pos:\n\u001B[1;32m   1511\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmoveto(\u001B[38;5;241m-\u001B[39mpos)\n",
      "File \u001B[0;32m~/.virtualenvs/nnets/lib/python3.10/site-packages/tqdm/std.py:350\u001B[0m, in \u001B[0;36mtqdm.status_printer.<locals>.print_status\u001B[0;34m(s)\u001B[0m\n\u001B[1;32m    348\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprint_status\u001B[39m(s):\n\u001B[1;32m    349\u001B[0m     len_s \u001B[38;5;241m=\u001B[39m disp_len(s)\n\u001B[0;32m--> 350\u001B[0m     \u001B[43mfp_write\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;130;43;01m\\r\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43ms\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mlast_len\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mlen_s\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    351\u001B[0m     last_len[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m len_s\n",
      "File \u001B[0;32m~/.virtualenvs/nnets/lib/python3.10/site-packages/tqdm/std.py:344\u001B[0m, in \u001B[0;36mtqdm.status_printer.<locals>.fp_write\u001B[0;34m(s)\u001B[0m\n\u001B[1;32m    342\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfp_write\u001B[39m(s):\n\u001B[1;32m    343\u001B[0m     fp\u001B[38;5;241m.\u001B[39mwrite(_unicode(s))\n\u001B[0;32m--> 344\u001B[0m     \u001B[43mfp_flush\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/nnets/lib/python3.10/site-packages/tqdm/utils.py:145\u001B[0m, in \u001B[0;36mDisableOnWriteError.disable_on_exception.<locals>.inner\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    144\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 145\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    147\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m e\u001B[38;5;241m.\u001B[39merrno \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m5\u001B[39m:\n",
      "File \u001B[0;32m~/.virtualenvs/nnets/lib/python3.10/site-packages/ipykernel/iostream.py:488\u001B[0m, in \u001B[0;36mOutStream.flush\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    486\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpub_thread\u001B[38;5;241m.\u001B[39mschedule(evt\u001B[38;5;241m.\u001B[39mset)\n\u001B[1;32m    487\u001B[0m     \u001B[38;5;66;03m# and give a timeout to avoid\u001B[39;00m\n\u001B[0;32m--> 488\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mevt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflush_timeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    489\u001B[0m         \u001B[38;5;66;03m# write directly to __stderr__ instead of warning because\u001B[39;00m\n\u001B[1;32m    490\u001B[0m         \u001B[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001B[39;00m\n\u001B[1;32m    491\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIOStream.flush timed out\u001B[39m\u001B[38;5;124m\"\u001B[39m, file\u001B[38;5;241m=\u001B[39msys\u001B[38;5;241m.\u001B[39m__stderr__)\n\u001B[1;32m    492\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/threading.py:607\u001B[0m, in \u001B[0;36mEvent.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    605\u001B[0m signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flag\n\u001B[1;32m    606\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[0;32m--> 607\u001B[0m     signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cond\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    608\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/threading.py:324\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    322\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    323\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 324\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    325\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    326\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m waiter\u001B[38;5;241m.\u001B[39macquire(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 2000\n",
    "DISPLAY_BATCHES = 8\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Run over the training examples\n",
    "    train_loss = 0\n",
    "    for batch, (sequence, target) in tqdm(enumerate(train)):\n",
    "        optimizer.zero_grad()\n",
    "        forced_target = target\n",
    "        # Alternate use of teacher forcing vs feeding back own inputs\n",
    "        if np.random.randint(2) == 0:\n",
    "            forced_target = target[:,0,:].unsqueeze(1)\n",
    "        hidden, pred = model(sequence, forced_target)\n",
    "        loss = loss_fn(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        # Show text generated from training prompt as an example\n",
    "        # Don't feed in all of the train y sequences, just the first token\n",
    "        # The other y tokens will be predicted by the model and fed back in\n",
    "        sents = generate(sequence[:DISPLAY_BATCHES], target[:DISPLAY_BATCHES])\n",
    "        for sent in sents:\n",
    "            print(sent)\n",
    "\n",
    "        # Compute validation loss.  Unless you have a lot of training data, the validation loss won't decrease.\n",
    "        valid_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch, (sequence, target) in enumerate(valid):\n",
    "                # Only feed in the first token of the actual target\n",
    "                hidden, pred = model(sequence, target[:,0,:].unsqueeze(1))\n",
    "                loss = loss_fn(pred, target)\n",
    "                valid_loss += loss.item()\n",
    "        print(f\"Epoch {epoch} train loss: {train_loss} valid loss: {valid_loss}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

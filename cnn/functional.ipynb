{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "IMAGE_DIR = \"images\"\n",
    "FOLDERS = [f for f in os.listdir(IMAGE_DIR) if \"DS_Store\" not in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "for i, folder in enumerate(FOLDERS):\n",
    "    fname = os.path.join(IMAGE_DIR, folder)\n",
    "    for im in os.listdir(fname):\n",
    "        impath = os.path.join(fname, im)\n",
    "        img = Image.open(impath)\n",
    "        data = np.asarray(img, dtype=\"int32\")\n",
    "        # Scale values from -1 to 1\n",
    "        data = ((data / 255) - .5) / .5\n",
    "        data = np.moveaxis(data, -1, 0)\n",
    "        target = np.zeros((1, len(FOLDERS)))\n",
    "        target[0,i] = 1\n",
    "        images.append((data, target, folder, ))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "outputs": [],
   "source": [
    "def log_loss(predicted, actual):\n",
    "    tol = 1e-6\n",
    "    predicted = predicted\n",
    "    actual = actual + tol\n",
    "    return (np.log(predicted) - np.log(actual))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "def softmax(preds):\n",
    "    preds = np.exp(preds)\n",
    "    return preds / np.sum(preds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "def init_layers(layer_defs):\n",
    "    layers = []\n",
    "    for i in range(1, len(layer_defs)):\n",
    "        if \"input_units\" in layer_defs[i]:\n",
    "            last_units = layer_defs[i][\"input_units\"]\n",
    "        else:\n",
    "            last_units = layer_defs[i-1][\"units\"]\n",
    "\n",
    "        biases = np.ones((1,layer_defs[i][\"units\"]))\n",
    "        if layer_defs[i][\"type\"] == \"cnn\":\n",
    "            weights = np.random.rand(layer_defs[i-1][\"units\"], layer_defs[i][\"units\"], layer_defs[i][\"kernel_size\"], layer_defs[i][\"kernel_size\"])\n",
    "        else:\n",
    "            weights = np.random.rand(last_units, layer_defs[i][\"units\"])\n",
    "\n",
    "        weights = weights / 5 - .1\n",
    "\n",
    "        layers.append([\n",
    "            weights,\n",
    "            biases,\n",
    "            layer_defs[i][\"type\"]\n",
    "        ])\n",
    "    return layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def unroll_image(image, kernel_x, kernel_y):\n",
    "    x_size = (image.shape[0] - (kernel_x - 1))\n",
    "    y_size = (image.shape[1] - (kernel_y - 1))\n",
    "    rows =  x_size * y_size\n",
    "    unrolled = np.zeros((rows, kernel_x * kernel_y))\n",
    "    for x in range(0, x_size):\n",
    "        for y in range(0, y_size):\n",
    "            unrolled[y + (x * y_size),:] = image[x:(x+kernel_x),y:(y+kernel_y)].reshape((1,kernel_x * kernel_y))\n",
    "    return unrolled\n",
    "\n",
    "def convolve(image, kernel):\n",
    "    return np.matmul(image, kernel.reshape(kernel.shape[0] * kernel.shape[1], 1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "def forward(batch, layers):\n",
    "    hidden = [batch.copy()]\n",
    "    for i in range(len(layers)):\n",
    "        if layers[i][2] == \"cnn\":\n",
    "            channels, next_channels, kernel_x, kernel_y = layers[i][0].shape\n",
    "\n",
    "            new_x = batch.shape[1] - (kernel_x - 1)\n",
    "            new_y = batch.shape[2] - (kernel_y - 1)\n",
    "            next_batch = np.zeros((next_channels, new_x , new_y))\n",
    "            for channel in range(channels):\n",
    "                unrolled = unroll_image(batch[channel,:], kernel_x, kernel_y)\n",
    "                for next_channel in range(next_channels):\n",
    "                    kernel = layers[i][0][channel, next_channel, :]\n",
    "                    mult = convolve(unrolled, kernel).reshape(new_x, new_y)\n",
    "                    next_batch[next_channel,:] += mult\n",
    "            next_batch /= batch.shape[0]\n",
    "\n",
    "            hidden.append(next_batch.copy())\n",
    "            next_batch = np.maximum(next_batch, 0)\n",
    "            batch = next_batch\n",
    "        else:\n",
    "            if layers[i-1][2] == \"cnn\":\n",
    "                batch = batch.reshape(batch.shape[0], batch.shape[1] * batch.shape[2])\n",
    "            batch = np.matmul(batch, layers[i][0]) + layers[i][1]\n",
    "            hidden.append(batch.copy())\n",
    "            if i < len(layers) - 1:\n",
    "                batch = np.maximum(batch, 0)\n",
    "\n",
    "    return layers, batch, hidden"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [],
   "source": [
    "layer_defs = [\n",
    "    {\"type\": \"input\", \"units\": 3},\n",
    "    {\"type\": \"cnn\", \"kernel_size\": 3, \"units\": 1},\n",
    "    {\"type\": \"dense\", \"input_units\": 254 * 254, \"units\": 5}\n",
    "]\n",
    "\n",
    "layers = init_layers(layer_defs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [],
   "source": [
    "layers, batch, hidden = forward(images[0][0], layers)\n",
    "lr = 5e-4\n",
    "grad = log_loss(softmax(batch), np.array([0,0,1,0,0]))\n",
    "\n",
    "i = 1\n",
    "grad = np.multiply(grad, np.heaviside(hidden[i+1], 1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [],
   "source": [
    "grad = grad.T\n",
    "w_grad = np.matmul(grad, hidden[i].reshape(1, math.prod(hidden[i].shape))).T\n",
    "b_grad = grad.T\n",
    "layers[i][0] -= (w_grad + layers[i][0] * .01) * lr\n",
    "layers[i][1] -= b_grad * lr\n",
    "grad = np.matmul(layers[i][0], grad).T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 64516)"
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [],
   "source": [
    "i = 0\n",
    "grad = grad.reshape(hidden[i+1].shape)\n",
    "grad = np.multiply(grad, np.heaviside(hidden[i+1], 1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [],
   "source": [
    "_, kernel_x, kernel_y = grad.shape\n",
    "flat_input = unroll_image(hidden[i][0,:], kernel_x, kernel_y)\n",
    "flat_grad = grad.reshape(math.prod(grad.shape), 1)\n",
    "k_grad = np.matmul(flat_input, flat_grad).reshape(1,1,layers[i][0].shape[2], layers[i][0].shape[3])\n",
    "layers[i][0] -= k_grad * lr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 1, 3, 3)"
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_grad.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [],
   "source": [
    "def backward(layers, hidden, grad, lr, verbose=False):\n",
    "    for i in range(len(layers)-1, -1, -1):\n",
    "        print(f\"Layer {i}\") if verbose else None\n",
    "\n",
    "        if layers[i][2] == \"cnn\":\n",
    "            grad = grad.reshape(hidden[i+1].shape)\n",
    "            if i != len(layers) - 1:\n",
    "                grad = np.multiply(grad, np.heaviside(hidden[i+1], 1))\n",
    "            _, kernel_x, kernel_y = grad.shape\n",
    "            for channel in range(hidden[i].shape[0]):\n",
    "                flat_input = unroll_image(hidden[i][channel,:], kernel_x, kernel_y)\n",
    "                flat_grad = grad.reshape(math.prod(grad.shape), 1)\n",
    "                k_grad = np.matmul(flat_input, flat_grad).reshape(1, 1, layers[i][0].shape[2], layers[i][0].shape[3])\n",
    "                print(f\"k_grad: {k_grad.shape}\") if verbose else None\n",
    "                layers[i][0] -= k_grad * lr\n",
    "        else:\n",
    "            if i != len(layers) - 1:\n",
    "                grad = np.multiply(grad, np.heaviside(hidden[i+1], 1))\n",
    "            grad = grad.T\n",
    "            print(f\"starting grad: {grad.shape}\") if verbose else None\n",
    "            w_grad = np.matmul(grad, hidden[i].reshape(1, math.prod(hidden[i].shape))).T\n",
    "            print(f\"w_grad: {w_grad.shape}\") if verbose else None\n",
    "            b_grad = grad.T\n",
    "\n",
    "            layers[i][0] -= (w_grad + layers[i][0] * .01) * lr\n",
    "            layers[i][1] -= b_grad * lr\n",
    "\n",
    "            grad = np.matmul(layers[i][0], grad).T\n",
    "            print(f\"ending grad: {grad.shape}\") if verbose else None\n",
    "    return layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xz/9z84c__j28g8tg28bmcthjj00000gn/T/ipykernel_12135/759320627.py:20: RuntimeWarning: divide by zero encountered in divide\n",
      "  print(f\"Epoch {epoch} iter {i} loss: {np.mean(epoch_loss / i)}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 iter 0 loss: nan\n",
      "Epoch 0 iter 50 loss: 8.13878648512592\n"
     ]
    }
   ],
   "source": [
    "layer_defs = [\n",
    "    {\"type\": \"input\", \"units\": 3},\n",
    "    {\"type\": \"cnn\", \"kernel_size\": 3, \"units\": 1},\n",
    "    {\"type\": \"dense\", \"input_units\": 254 * 254, \"units\": 5}\n",
    "]\n",
    "lr = 5e-6\n",
    "epochs = 1\n",
    "\n",
    "layers = init_layers(layer_defs)\n",
    "for epoch in range(epochs+1):\n",
    "    epoch_loss = np.zeros(images[0][1].shape)\n",
    "    for i, img in enumerate(images):\n",
    "        image, target, label = img\n",
    "        layers, batch, hidden = forward(image, layers)\n",
    "\n",
    "        grad = log_loss(softmax(batch), target)\n",
    "        epoch_loss += grad\n",
    "        layers = backward(layers, hidden, grad, lr)\n",
    "        if i % 50 == 0:\n",
    "            print(f\"Epoch {epoch} iter {i} loss: {np.mean(epoch_loss / i)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
